<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cdp | @ijin]]></title>
  <link href="http://ijin.github.com/blog/categories/cdp/atom.xml" rel="self"/>
  <link href="http://ijin.github.com/"/>
  <updated>2013-11-12T15:38:15+09:00</updated>
  <id>http://ijin.github.com/</id>
  <author>
    <name><![CDATA[Michael H. Oshita]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[リージョン間高速データ転送]]></title>
    <link href="http://ijin.github.com/blog/2013/04/03/accelerating-cross-region-data-transfer/"/>
    <updated>2013-04-03T09:05:00+09:00</updated>
    <id>http://ijin.github.com/blog/2013/04/03/accelerating-cross-region-data-transfer</id>
    <content type="html"><![CDATA[<p>先日の<a href="http://jaws-ug.jp/jawsdays2013/">JAWS DAYS</a>のセッション<a href="http://www.publickey1.jp/blog/13/obama_for_america.html">「Behind the scenes of Presidential Campaign」</a>でリージョン間のデータ転送を高速化するツールとして<a href="http://tsunami-udp.sourceforge.net">tsunami udp</a>と<a href="http://www.cloudopt.com">cloudopt</a>を使った話が出てたので試してみました。</p>

<p>通常、遠距離のサーバはRTTが大きくなるのでスループットが下がり、巨大なデータ転送には苦労しますが、なんと27TBを9時間で転送したとのこと！実際はマシンを並列にして同時転送したらしいので1台での実験です。</p>

<h3>前提</h3>

<ul>
<li>東京(server1) -> アメリカ西海岸(server2)</li>
<li>RTT: 120msぐらい</li>
<li>EC2 instance type: m1.large</li>
<li>OS: Ubuntu 12.04</li>
</ul>


<h3>ベーステスト</h3>

<p>10Gファイルの作成</p>

<pre><code>server1$ mkdir _tmp; cd _tmp
server1$ dd if=/dev/zero of=10G count=1 bs=1 seek=10G
</code></pre>

<p>転送</p>

<pre><code>server1$ scp -rp 10G server2:
10G     100%   10GB  11.1MB/s   15:22
</code></pre>

<p>だいたい、90Mbpsぐらい。</p>

<h3>Tsunami UDP</h3>

<p>インストールは両サーバで</p>

<pre><code>sudo apt-get install make gcc autoconf
wget http://downloads.sourceforge.net/project/tsunami-udp/tsunami-udp/tsunami-v1.1-cvsbuild42/tsunami-v1.1-cvsbuild42.tar.gz
tar xvfz tsunami-v1.1-cvsbuild42.tar.gz
cd tsunami-udp-v11-b42
make
sudo make install
</code></pre>

<p>tsunami udpはfetch型の作りなので、送信側のサーバ（server1）で対象ファイルのあるディレクトリに移動してサービス起動</p>

<pre><code>server1$ cd _tmp
server1$ tsunamid *
</code></pre>

<p>で、クライアント(server2)からファイルをfetch</p>

<pre><code>server2$ tsunami connect ec2-xx-x-xx-x-x get 10G quit
</code></pre>

<p>本当はftp-likeは対話型クライアントだけど、ワンライナーでも可能。  <br/>
転送が完了するとクライアント側で情報が出力されます。</p>

<pre><code>Transfer complete. Flushing to disk and signaling server to stop...
!!!!
PC performance figure : 224947 packets dropped (if high this indicates receiving PC overload)
Transfer duration     : 419.32 seconds
Total packet data     : 183339.18 Mbit
Goodput data          : 181958.17 Mbit
File data             : 81920.00 Mbit
Throughput            : 437.23 Mbps
Goodput w/ restarts   : 433.93 Mbps
Final file rate       : 195.36 Mbps
Transfer mode         : lossless
</code></pre>

<p>おお、確かに速い！スループットもセッションでも言ってた476Mbpsに近いし。</p>

<p>サーバ側では</p>

<pre><code>Server 1 transferred 10737418241 bytes in 419.33 seconds (195.4 Mbps)
</code></pre>

<p>ファイル自身の実際の転送レートはFinal file rateである<strong>195.4Mbps</strong>。
多分、パラメータチューニングやより速いディスクを使うとスループットはさらに向上すると予想。</p>

<h3>cloudopt</h3>

<p>次は圧縮、TCP最適化、data deduplication等、様々な技術を用いてWANを高速化する<a href="http://www.cloudopt.com">cloudopt</a>の実験。こちらは有料で、ソフトウェアをインストールしてライセンスを購入（15日間のお試しあり）して使う方法とAmazon Marketplaceでセットアップ済みの課金型AMIを起動する方法がとれます。今回はてっとり早く後者で。</p>

<p>AMIはMarketplaceでCloudoptを検索し、各リージョンで1台づつ起動。</p>

<p><img src="https://lh5.googleusercontent.com/-7PWSb_8ClIo/UVuL_bzBeAI/AAAAAAAAAtc/8Lw_bDnaPVE/s665/cloudopt_marketplace_+2013-03-30+at+2.08.07+PM.png"></p>

<p>Ubuntuベースなのが良いですね。</p>

<p>まずscpから呼べるcloudcopyを使っての転送</p>

<pre><code>server1$ scp -rp -S cloudcopy 10G server2:
10G                 100%   10GB  41.5MB/s   04:07     
CloudCopy transferred 17.22 MB, saving 99.8% of bandwidth by sending 9.983 fewer GB 
</code></pre>

<p>お、速い。しかしよく見てみると17.22MBしか転送されてません。どうやらファイル自体が全てゼロ埋めなので圧縮とdeduplicationが最大限効いているみたい。</p>

<p>では、今度は実際のDBのバックアップで転送実験（容量14GB）</p>

<pre><code>server1$ scp -rp -S cloudcopy dbbackup.tar server2:
dbbackup.tar                100%   14GB  11.2MB/s   20:42   
CloudCopy transferred 6.041 GB, saving 55.5% of bandwidth by sending 7.528 fewer GB
</code></pre>

<p>スループットはほぼ一緒だけど、転送容量が削減できてます。</p>

<p>一度転送したファイルはbyte cacheされるので、次に転送する時は差分だけ送るので高速化されます。</p>

<pre><code>server2$ rm dbbackup.tar 

server1$ tar rvf dbbackup.tar file
server1$ scp -rp -S cloudcopy dbbackup.tar server2:
dbbackup.tar                100%   14GB  20.0MB/s   11:35  
CloudCopy transferred 59.57 MB, saving 99.6% of bandwidth by sending 13.511 fewer GB
</code></pre>

<h3>リージョン間レプリケーション</h3>

<p>次はMySQLのレプリケーション実験。</p>

<p>各インスタンスでのピア設定</p>

<pre><code>server1$ sudo cloudconfig peer_add server2 server2_local_ip(10.x.x.x)
server2$ sudo cloudconfig peer_add server1 server1_local_ip(10.x.x.x)
</code></pre>

<p>これでcloudoptを使ったサーバ間のトンネルが確立されます。MySQLのレプリケーションはprivate ipでの設定が必要。
一通りレプリケーションが出来き、スレーブIOを停止した状態でマスターにしばらく書き込んだのちに再開すると、binlogが転送されるのでcloudstatsコマンドで統計が見れます。</p>

<pre><code>Component - cloudoptimizer
------------------------------------------------------------
           Number of connections:                    1
              Original data size:            111.96 MB
           Transferred data size:             52.44 MB

            Bandwidth Saving:             59.51 MB (53.2%)
</code></pre>

<p><strong>53.2%</strong>の転送容量削減！</p>

<h3>結論</h3>

<p>以上を組み合わせれば、新たなCDP候補である「<strong>リージョン間レプリケーションパターン (Cross-Region Replication Pattern)</strong>」が実現できます。</p>

<ul>
<li>巨大データをリージョン間で転送するにはtsunami udpが有効そう</li>
<li>リージョン間での差分バックアップやレプリケーション向けにはcloudoptで高速化</li>
<li>普通のHTTP通信とかも使えるかも</li>
<li>s3へのアップロード高速化も対応しているのでいずれ試してみたい</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Auto Scalingの設定とデプロイ方法]]></title>
    <link href="http://ijin.github.com/blog/2012/12/03/cdp/"/>
    <updated>2012-12-03T01:34:00+09:00</updated>
    <id>http://ijin.github.com/blog/2012/12/03/cdp</id>
    <content type="html"><![CDATA[<p><a href="http://www.zusaar.com/event/451061">CDP Advent Calendar 2012</a>に登録しました。ここ1年ちょいで使い慣れてきたパターンがあり、作った当時はクラウドデザインパターンはなかったのですが、<a href="http://aws.clouddesignpattern.org/index.php/CDP:Clone_Server%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3">Clone Server</a>と<a href="http://aws.clouddesignpattern.org/index.php/CDP:Scale_Out%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3">Scale Out</a>パターンの組合せに当てはまると思うので紹介します。ちなみにアプリはRails。</p>

<p>常にデプロイして更新し続けるシステムを手動、あるいは自動スケールアウトする時に便利な手法だったりします。</p>

<p>図にするとこんな感じですかね。</p>

<p><img src="https://lh4.googleusercontent.com/-eDSfSiz0XhU/ULyOlKj_JKI/AAAAAAAAArw/QzSfVJeeUfw/w727-h490-p-k/CDP_Clone%252BScale_Out.png"></p>

<h2>Auto Scaling設定</h2>

<h3>Launch Config</h3>

<p>まず、ベースとなるAMIの起動インスタンスサイズやセキュリティーグループを定義したLaunch Configを設定。</p>

<pre><code>as-create-launch-config cdp-lc --image-id ami-22a51d23 --instance-type m1.small \
--group cdp_web, cdp_admin
</code></pre>

<h3>Scaling Group</h3>

<p>次に、Scaling Groupで適用するAvailability Zone、インスタンス数の最小・最大閾値設定、紐尽くELB、死活監視方法・開始待ち時間、タグ等を定義。（ec2addtagではスペース入りのキーを設定できるのにas-create-auto-scaling-groupではできないので注意。早く直して。。）</p>

<pre><code>as-create-auto-scaling-group cdp-sg --launch-configuration cdp-lc \
--availability-zones ap-northeast-1a  --min-size 1 --max-size 9 --load-balancers cdp \
--health-check-type ELB --grace-period 300 --tag "k=Name, v=web.cdp" --tag "k=Use_Case, v=Test"
</code></pre>

<h3>Scaling Out Policy</h3>

<p>Scaling Outのポリシー設定。以下の例ではインスタンス1台を追加し、次のスケールアクションまでは5分間待機。ポリシーのARN (Amazon Resource Name)が出力されるので控えます。</p>

<pre><code>as-put-scaling-policy CDPOut --auto-scaling-group cdp-sg --adjustment 1 --type ChangeInCapacity \
--cooldown 300

&gt; arn:aws:autoscaling:ap-northeast-1:494850320039:scalingPolicy:d0d4dcf1-fb44-428a-a19c-38946633acf5:autoScalingGroupName/cdp-sg:policyName/CDPOut
</code></pre>

<h3>Cloudwatchトリガー（Scaling Out）</h3>

<p>Cloudwatchで閾値を超えたらスケールアウトするように設定。以下の例では対象Scaling Group配下のインスタンス達のCPUが1分間で平均75%以上で推移した場合、先ほど設定したScaling OutポリシーがARN経由で実行されます。また、閾値を超過あるいは下回った場合にSNS経由でアラートメールを飛ばします。</p>

<pre><code>mon-put-metric-alarm  CDPHighCPUAlarm --comparison-operator GreaterThanThreshold \
--evaluation-periods 1 --metric-name CPUUtilization --namespace "AWS/EC2" --period 60 \
--statistic Average --threshold 75 --dimensions "AutoScalingGroupName=cdp-sg" \
--ok-actions arn:aws:sns:ap-northeast-1:494850320039:cdp-alert --alarm-actions \
arn:aws:sns:ap-northeast-1:494850320039:cdp-alert, arn:aws:autoscaling:ap-northeast-1:494850320039:scalingPolicy:d0d4dcf1-fb44-428a-a19c-38946633acf5:autoScalingGroupName/cdp-sg:policyName/CDPOut
</code></pre>

<h3>Scaling Down Policy</h3>

<p>同じくScaling Downのポリシー設定。インスタンスが起動すると最低1時間は課金されるので頻繁に伸縮するともったいないのでスケールダウンアクションはゆっくりやるのがポイントです。</p>

<pre><code>as-put-scaling-policy CDPDown --auto-scaling-group cdp-sg --adjustment=-1 \
--type ChangeInCapacity --cooldown 1500

&gt; arn:aws:autoscaling:ap-northeast-1:494850320039:scalingPolicy:de53fbd5-130c-46a8-bf47-25e29f7d358e:autoScalingGroupName/cdp-sg:policyName/CDPDown
</code></pre>

<h3>Cloudwatchトリガー（Scaling Down）</h3>

<p>スケールダウンのトリガーは平均CPUが35%を25分間下回った場合に実行されます。この閾値周辺のアラートメールはいらないので設定してません。</p>

<pre><code>mon-put-metric-alarm CDPLowCPUAlarm --comparison-operator LessThanThreshold \
--evaluation-periods 1 --metric-name CPUUtilization --namespace "AWS/EC2" --period 1500 \
--statistic Average --threshold 35 --dimensions "AutoScalingGroupName=cdp-sg" --alarm-actions \
arn:aws:autoscaling:ap-northeast-1:494850320039:scalingPolicy:de53fbd5-130c-46a8-bf47-25e29f7d358e:autoScalingGroupName/cdp-sg:policyName/CDPDown
</code></pre>

<h3>通知</h3>

<p>最後にスケールアクション時に通知が飛ぶように設定。例えば、あるインスタンスが不調により反応がなく、ポリシーによってリプレースされる場合に飛んだりします。</p>

<pre><code>as-put-notification-configuration cdp-sg -t arn:aws:sns:ap-northeast-1:494850320039:cdp-alert \
-n autoscaling:EC2_INSTANCE_LAUNCH, autoscaling:EC2_INSTANCE_TERMINATE, \
autoscaling:EC2_INSTANCE_LAUNCH_ERROR, autoscaling:EC2_INSTANCE_TERMINATE_ERROR
</code></pre>

<h2>APP側の設定</h2>

<h3>ソースコード同期</h3>

<p>同期には起動時にupstart経由でrsyncを叩いて管理サーバから最新ソースを取ってきてサービスを再起動します。転送時の圧縮モードはarcfourが一番スループットが出たのでそれに。</p>

<p><div><script src='https://gist.github.com/4191986.js?file='></script>
<noscript><pre><code># sync source code
description &quot;Update source code&quot;

start on filesystem
stop on shutdown

task
console output

script
time sudo -u deploy rsync -av --delete -e 'ssh -c arcfour -i /home/deploy/.ssh/id_dsa -o StrictHostKeyChecking=no' deploy@admin.cdp:/usr/local/apps/project/ /usr/local/rails_apps/project &gt;&gt; /mnt/update.log 2&gt;&amp;1
/etc/init.d/unicorn upgrade &gt;&gt; /mnt/update.log 2&gt;&amp;1
/etc/init.d/nginx restart &gt;&gt; /mnt/update.log 2&gt;&amp;1
end script
</code></pre></noscript></div>
</p>

<h2>Capistrano</h2>

<p>デプロイはマスターサーバ（管理兼）上でCapistranoを実行し、ELB配下の生きているインスタンスに対して更新をかけます。deploy.rbに追加する記述は以下の通り。昔はec2 api toolsを直接呼んでパースしたりしてコードが長かったのですが、今は<a href="http://aws.amazon.com/sdkforruby/">AWS SDK for Ruby</a>があり、<a href="http://aws.amazon.com/iam/">IAM role</a>でinstance profileを設定すればわずか数行でできてしまいます！</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="nb">require</span> <span class="s1">&#39;aws-sdk&#39;</span>
</span><span class='line'><span class="no">AWS</span><span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="ss">:ec2_endpoint</span> <span class="o">=&gt;</span> <span class="s1">&#39;ec2.ap-northeast-1.amazonaws.com&#39;</span><span class="p">,</span> <span class="ss">:elb_endpoint</span> <span class="o">=&gt;</span> <span class="s1">&#39;elasticloadbalancing.ap-northeast-1.amazonaws.com&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">instances</span> <span class="o">=</span> <span class="no">AWS</span><span class="o">::</span><span class="no">ELB</span><span class="o">.</span><span class="n">new</span><span class="o">.</span><span class="n">load_balancers</span><span class="o">[</span><span class="s1">&#39;cdp&#39;</span><span class="o">].</span><span class="n">instances</span><span class="o">.</span><span class="n">select</span><span class="p">{</span><span class="o">|</span><span class="n">i</span><span class="o">|</span> <span class="n">i</span><span class="o">.</span><span class="n">exists?</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">i</span><span class="o">.</span><span class="n">elb_health</span><span class="o">[</span><span class="ss">:state</span><span class="o">]</span> <span class="o">==</span> <span class="s2">&quot;InService&quot;</span><span class="p">}</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="ss">:public_dns_name</span><span class="p">)</span>
</span><span class='line'><span class="n">servers</span> <span class="o">=</span> <span class="n">instances</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="s2">&quot;localhost&quot;</span>
</span><span class='line'><span class="n">role</span> <span class="ss">:app</span> <span class="k">do</span> <span class="n">servers</span> <span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h2>注意点</h2>

<ul>
<li>同期するファイル数が多すぎる（数十万個）と、チェックサム比較で時間がかかってしまい同期が終了する前にAuto Scalingの死活監視によってインスタンスがterminateされ、またlaunchされterminateされるという恐怖のスケールループ地獄に陥る。。。（これ、制限できないのかな）</li>
<li>あらかじめトラフィック増の時間帯が分かっていたら<a href="http://docs.amazonwebservices.com/AutoScaling/latest/DeveloperGuide/scaling_plan.html#schedule_time">Scheduled Action</a>で多めに設定しておいて自動スケールダウンさせた方が吉。</li>
<li>マスタサーバがSPOFとなりうるので冗長化する、もしくはrsyncよりs3経由にした方が良い。</li>
<li>急激なトラフィック増ではELB自体のスケールが追いつかない場合も。</li>
</ul>

]]></content>
  </entry>
  
</feed>
