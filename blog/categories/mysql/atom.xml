<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: mysql | @ijin]]></title>
  <link href="http://ijin.github.io/blog/categories/mysql/atom.xml" rel="self"/>
  <link href="http://ijin.github.io/"/>
  <updated>2019-04-19T04:27:51+09:00</updated>
  <id>http://ijin.github.io/</id>
  <author>
    <name><![CDATA[Michael H. Oshita]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ConsulによるMySQLフェールオーバー]]></title>
    <link href="http://ijin.github.io/blog/2014/07/11/mysql-failover-with-consul/"/>
    <updated>2014-07-11T10:12:00+09:00</updated>
    <id>http://ijin.github.io/blog/2014/07/11/mysql-failover-with-consul</id>
    <content type="html"><![CDATA[<p>先日(6/22/14)、6月なのにどういう分けか早めに開催された<a href="http://2014.techfesta.jp/">July Tech Festa 2014</a>でConsulについて<a href="http://2014.techfesta.jp/p/program.html?m=1#c43">発表</a>してきた。そのユースケースの一つとしてMySQL failoverをちょっとだけ紹介したので、ここに詳しく書いておく。</p>

<h2>MHA</h2>

<p>MySQLレプリケーションの障害時にフェールオーバーしたい場合、MHAを使うの結構ポピュラー（日本では）だと思います。MHAは最新binlogの適用、Slaveの昇格とレプリケーションの張替えまではやってくれますが、実際のフェールオーバーの部分はユーザに委ねられていて、master_ip_failover_scriptのテンプレートをカスタマイズするか独自実装する必要があり、一般的な実現方法としてはカタログデータベースの更新かVirtual IPの切替等があります。</p>

<p>Virtual IPだと居残りセッションの問題や切替の保証難しかったり、そもそも環境によっては使えなかったりするので、私はあんまり好きじゃありません。また以前、後者的アプローチとしてAWSのVPC内であればrouting tableを変更する事によってこの挙動に似た実現方法を<a href="/blog/2013/05/21/custom-non-rds-multi-az-mysql-replication/">紹介</a>した事がありますが、一番の問題点はAPI backplaneがSPoFになってて、ここが落ちたらそもそも動かない；また、APIのrate limitに達して呼び出しさえ出来ないという結構痛い目に会ったりします。</p>

<p>そこで前者的なアプローチとしてmasterの情報を管理するカタログデータベースの更新部分にConsulを使ってみました。</p>

<h2>CONSUL</h2>

<p>ConsulとはHTTP APIとDNSで操作ができる分散型クラスタで、VagrantやSerf等を開発しているHashicorpの新プロダクトです。Key featureは以下のとおり。</p>

<ul>
<li>Service Discovery</li>
<li>Failure Detection</li>
<li>Multi Datacenter</li>
<li>Key/Value Store</li>
</ul>


<h3>ConsulのConsistencyについて</h3>

<p>ConsulはCAP定理でいうCPという特性をもっており、Consistency（一貫性）に重きをおいてあります。Paxosを由来とするRaftをベースにしたconsensus protocolで実現していて、ピアセット内の各サーバノードでlog entryの書き込みがquorumで決定された後にcommitされたと見なされ、FSMに書き込まれます。よって、書き込みに関してはStrongly Consistentな処理となります。読み込みに関しては、パフォーマンス要求に応じてConsistencyレベルをクエリータイプによって調整可能（まるでCassandraのように！）で、Usually Consistent, Strongly Consistent, Staleから選択可能です。DNSベースのクエリーはデフォルトで単一のリーダーノードが返答するのでStrongly Consistentな処理となっています。（Staleにする事も可能）</p>

<h2>ConsulとMHAの連携概要</h2>

<ul>
<li>Consulを内部DNSとして使い、clientはDNSベースでmasterに接続</li>
<li>MySQL masterはAPIで予めサービス名（alias DNS）を登録しておく</li>
<li>mysql_failover_scriptで旧情報の削除と新情報の登録をやる

<ul>
<li>旧master IPを無効化する部分でConsulのCatalog endpointを使ってderegister (/v1/catalog/deregister)</li>
<li>新master ipを登録する部分でConsulのCatalog endpointを使ってregister (/v1/catalog/register)</li>
<li>成功しない限り進まない（exit code check）</li>
</ul>
</li>
<li>削除、及び登録はconsulのconsistency modelによって一貫性は保証される</li>
</ul>


<h2>DEMO</h2>

<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/rA4hyJ-pccU "></iframe></div></p>

<h2>Notes</h2>

<p>DNSは最新のv0.3.0になってからTTLを設定できるようになったので、Amazon RDSっぽい感じのフェールオーバーも可能ですが、v0.2系に比べて格段にパフォーマンスが向上（スライド参照）したので、デフォルトのTTL 0でも問題ない範囲になってる感じです。また、もうちょっと詳しい内容は今度の<a href="http://connpass.com/event/7322/">#hbstudy</a>で話す予定です。</p>

<h2>スライド</h2>

<p>以下、July Tech Festa 2014で発表した時のスライドです。</p>

<p><script async="true" class="speakerdeck-embed" data-id="e07317d0dc040131a0982229a5c1e016" src="//speakerdeck.com/assets/embed.js"> </script></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[i2 instanceでMySQLベンチマーク]]></title>
    <link href="http://ijin.github.io/blog/2014/01/01/mysql-benchmarks-on-aws-i2-instance-ssds/"/>
    <updated>2014-01-01T00:00:00+09:00</updated>
    <id>http://ijin.github.io/blog/2014/01/01/mysql-benchmarks-on-aws-i2-instance-ssds</id>
    <content type="html"><![CDATA[<p>新年明けました。おめでとうございます。</p>

<p>すっかり12月の<a href="http://www.zusaar.com/event/1117005">aws</a>/<a href="http://www.zusaar.com/event/1847003">mysql</a> advent calendarに乗り遅れたので、AWSのi2 instanceでのMySQLのベンチマークを勝手におまけとして公表します。
以前取ったhi1.4xlargeとの比較になります。</p>

<h2>構築</h2>

<p>SSDディスクはAWSが<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/i2-instances.html#i2-instances-diskperf">推奨する</a>over-provisioningを有効にする為に10%を非partitionし、それぞれ720Gでパーティション作成。</p>

<pre><code>sudo mdadm --create /dev/md0 --level 0 --raid-devices 8 /dev/xvdb1 /dev/xvdc1  /dev/xvdd1 /dev/xvde1 /dev/xvdf1 /dev/xvdg1 /dev/xvdh1 /dev/xvdi1
sudo mkfs.xfs -f -b size=4096 -i size=512 -l size=64m /dev/md0
sudo mount -t xfs -o noatime,logbufs=8 /dev/md0 /data
</code></pre>

<p>OSはkernel versionが3.8以上が<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/i2-instances.html#i2-instances-diskperf">望ましい</a>のでいつものLTSではなく、Ubuntu Server 13.10のHVMタイプ (ami-b93264d0)</p>

<h2>sysbench</h2>

<p>やり方やパラメータは<a href="/blog/2013/02/22/mysql-benchmarks-on-aws-ssd-vs-fusion-io/">前回</a>の計測方法と同じ。i2.8xlaregは32coreですが、今回はhi1.4xlargeの時と比較する為に敢えて16スレッドで計測しました。</p>

<ul>
<li>sysbenchのoltpモード</li>
<li>データサイズは12G（5000万件）</li>
<li>readonly</li>
<li>uniform（フルスキャン）</li>
</ul>


<p>コマンド</p>

<pre><code>time sysbench --test=oltp --oltp-table-size=50000000 --db-driver=mysql --mysql-user=root --num-threads=16 --max-requests=0 --max-time=180 --init-rng=on --oltp-read-only=on --oltp-dist-type=uniform 2&gt;&amp;1 run
</code></pre>

<p>トランザクション推移</p>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=5&amp;zx=jwv2ytp6xwx3"></p>

<p>レスポンスタイム推移</p>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=6&amp;zx=sfl6ocblw5ob"></p>

<p>速いですね。</p>

<h2>tpcc-mysql</h2>

<p>こちらも<a href="/blog/2013/02/22/mysql-benchmarks-on-aws-ssd-vs-fusion-io/">前回</a>)の計測方法と同じ。</p>

<ul>
<li>500 warehouses (50GBぐらい)</li>
<li>24GB Buffer pool</li>
<li>16スレッド</li>
<li>1時間実行</li>
</ul>


<p>コマンド</p>

<pre><code> tpcc_load localhost tpcc root "" 500
 tpcc_start -d tpcc -u root -p "" -w 500 -c 16 -r 300 -l 3600
</code></pre>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=7&amp;zx=fc6nz8iel3ez"></p>

<p>hi1.4xlargeはSSD1台で計測した事を考えると、同価格帯のi2.4xlarge（SSD4台）の半分（SSD2台）のパフォーマンスが出るのは妥当ですね。</p>

<h2>fio</h2>

<p>ついでにfioでそれぞれRAID0した場合のベンチマークも取ってみたけど、<a href="http://d.hatena.ne.jp/rx7/20131224/p1">並河さん</a>と結果が違ってwriteがスケールしてます。OSとmkfs.xfsのオプションしか違わないはずだけど。。</p>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=9&amp;zx=v7nbywda04bp"></p>

<h2>その他</h2>

<p>いやー。spot instanceがないので計測だけで結構かかってしまった。</p>

<p>しかし、なんでhi1世代の次はhi2ではなく、i2なんだろう。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Non-RDSなオレオレMulti-AZ MySQL Replication]]></title>
    <link href="http://ijin.github.io/blog/2013/05/21/custom-non-rds-multi-az-mysql-replication/"/>
    <updated>2013-05-21T18:03:00+09:00</updated>
    <id>http://ijin.github.io/blog/2013/05/21/custom-non-rds-multi-az-mysql-replication</id>
    <content type="html"><![CDATA[<p>先日（5/17/13）<a href="http://www.zusaar.com/event/668006">cloudpack night #6 - Re:Generate -</a>に参加してきました。</p>

<p>当日の様子はcloudpack<a href="https://twitter.com/yoshidashingo">吉田</a>さんの以下のレポートで。<br />
<a href="http://d.hatena.ne.jp/yoshidashingo/20130518/1368853720">cloudpack Night #6 - re:Generate - を開催しました</a></p>

<p>私はDJを少々とLTで参加させて頂いたのでその内容になります。</p>

<h2>オレオレMulti-AZのススメ</h2>

<p>AWS上でMySQLを使う場合、RDSはてっとり早くて良いんですが、たまにもうちょっと柔軟性が欲しい時があります。
例えば別のストーレジエンジンやディストリビューションを使ったり（Percona Server, MariaDB, TokuDB, Mronnga等）、RDSでは使えないインスタンスファミリー（hi1, m3, c1系）を使ったり、OSレベルでのチューニングができたり、スレーブのバッファプールを予め温めておいたり。等々。</p>

<p>しかし、RDSにはAvailability Zone (AZ)をまたいでフェールオーバーするMulti-AZ機能があり、AWSで設計するにはAZ障害を考慮した方が推奨されます。</p>

<p>そこで、MHAとVPCを組み合わせて柔軟性をもったMulti-AZ環境を実現します。
（ちなみに私の場合はhi1.4xlargeでPercona Serverを冗長化をする必要があったから）</p>

<h3>MHA</h3>

<p><a href="https://code.google.com/p/mysql-master-ha/">MHA</a>とはFacebookの<a href="http://yoshinorimatsunobu.blogspot.jp/">松信</a>さんがDeNA時代に作ったMySQLの自動フェールオーバーしてくれうナイスなツールです。Master障害時にbinlog同期とSlaveの昇格を全自動でやってくれます。昇格時にはカタログデータベースに更新をかけて新DB構成のIPの情報を更新するか、Virtual IPを切り替えるかをする必要（この担当部分はmaster_ip_failover_scriptで対応）があるけど、今回は後者的なアプローチになります。</p>

<h3>VPC</h3>

<p>ENIを使えばVirtual IP的な使い方はできるけどAZは超えられないので、source/dest. checkを無効化した上でrouting tableによって擬似Virtual IPを実現する<a href="http://aws.clouddesignpattern.org/index.php/CDP:Routing-Based_HA%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3">Routing-Based HAパターン</a>（CDP 2.0候補）を使います。ADSJ<a href="https://twitter.com/c9katayama">片山</a>さんの<a href="http://d.hatena.ne.jp/c9katayama/20111225/1324837509">エントリ</a>が発端ですね。</p>

<h2>Demo</h2>

<p>以下、LT時に見せたデモ動画</p>

<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/tovb29K6ddc "></iframe></div></p>

<p>擬似Virtual IPに対してそれぞれread/writeを行いつつMasterのプロセスをkillすると、通信できなくエラーが出続けるが20秒以内に自動フェールオーバーが完了しread/write共に再開します。pingも平均0.5msから2.0msに変わった事からAZが移った事が確認できます。</p>

<p>RDSのMulti-AZの場合、フェールオーバーには3-6分かかるので、かなり短時間で復旧が可能です。
また、RDSはCNAME切替によるDNSベースに対して、MHA+VPC構成の場合はIP指定することができます。そうするとアプリからのresolveが不要になり、去年起こった内部DNSが引けない障害が起きても問題ありません。</p>

<h2>注意点</h2>

<ul>
<li>RDSな自動バックアップがない

<ul>
<li>Xtrabackupとbinlogの定期s3保存で対応</li>
</ul>
</li>
<li>Point in Timeリカバリー

<ul>
<li>Chef等で自動化しましょう</li>
</ul>
</li>
<li>Read Replicaの作成

<ul>
<li>Chefで頑張りましょう</li>
</ul>
</li>
<li>学習曲線

<ul>
<li>勉強しましょう</li>
</ul>
</li>
<li>API backplaneがSPoF

<ul>
<li>AWSに祈りましょう</li>
</ul>
</li>
</ul>


<p>特に一番の懸念点は最後のAPI backplane。AWSの今までの大規模障害状況を見ていると、皆が同時に復旧をしようとしAPIへのリクエストが大量に集中してそこがボトルネックになり、リソースの操作不能に陥るという悲惨な事象が何回かありました。まあ、その場合はRDSでも同じような気はしますが、ここは当時の障害を経験にキャパシティが増加されている事を信じておくしかありませんね。。</p>

<h2>おわりに</h2>

<p>とまあ、こんなLTをしたわけですが、この後に続いたCookpadの<a href="https://twitter.com/sgwr_dts">菅原</a>さんの<a href="http://www.slideshare.net/winebarrel/ec2keepalivedlvsdsr">LT</a>の方が盛り上がって自分のは余興に終わってしまいました。</p>

<p>あ、ついでにその日はcpniteの資料作成やDJの選曲であんまり寝てなかったにもかかわらず、無事AWSソリューションアーキテクト（Associate）の認定試験に受かりました！</p>

<p><img src="https://lh5.googleusercontent.com/-d_HVsb6DgBc/UZs39XB1KGI/AAAAAAAAAuw/ntgPp33hcOI/w294-h120-no/Solutions-Architect-Associate.png"></p>

<h2>LTスライド</h2>

<p><div class="embed-ss-container"><iframe src="http://www.slideshare.net/slideshow/embed_code/21341276 "></iframe></div></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS SSD (hi1.4xlarge) vs Fusion-IOでのMySQLベンチマーク]]></title>
    <link href="http://ijin.github.io/blog/2013/02/22/mysql-benchmarks-on-aws-ssd-vs-fusion-io/"/>
    <updated>2013-02-22T17:32:00+09:00</updated>
    <id>http://ijin.github.io/blog/2013/02/22/mysql-benchmarks-on-aws-ssd-vs-fusion-io</id>
    <content type="html"><![CDATA[<p>（※ <a href="#add">追記</a>しました - 5/19/13）</p>

<p>巷ではMySQL 5.6 GAが出て騒がしいですが、ちょっと前に5.5系でAWSのSSDインスタンス（hi1.4xlarge）に載せ替える案件があったので、その時に取ったベンチマークを公表します。以前Fusion-IO (ioDrive Duo)でも同じようにやったので、比較になれば。</p>

<h2>経緯</h2>

<ul>
<li>あるウェブサービスのDBサイズが巨大でm2.4xlargeでも辛くなってきている</li>
<li>アクセスパターンによりパーティショニングが効かない</li>
<li>シャーディングをするにはアプリ改修が大変</li>
<li>数週間後に急激なアクセスが予想され、時間的余裕がない！</li>
<li>データサイズの急激な増加によりbuffer poolから溢れ、ディスクアクセスのさらなる発生が懸念</li>
</ul>


<p>というわけで、時間がないのでSSDへの移行を検討し、ベンチマークを取りました。</p>

<h2>ベンチマーク</h2>

<p>buffer poolが徐々に足りなくなった場合のディスクアクセスの発生をシミュレート</p>

<ul>
<li>sysbenchのoltpモード</li>
<li>データサイズは12G（5000万件）</li>
<li>readonly</li>
<li>uniform（フルスキャン）</li>
</ul>


<p>主要my.cnfパラメータ</p>

<pre><code> sync_binlog = 0
 innodb_buffer_pool_size = XXG
 innodb_flush_method = O_DIRECT
 innodb_flush_log_at_trx_commit = 1
 innodb_file_per_table
 innodb_io_capacity = 2000
</code></pre>

<p>コマンド</p>

<pre><code> time sysbench --test=oltp --oltp-table-size=50000000 --db-driver=mysql --mysql-user=root prepare                                                                                                         
 time sysbench --test=oltp --oltp-table-size=50000000 --db-driver=mysql --mysql-user=root --num-threads=16 --max-requests=0 --max-time=180 --init-rng=on --oltp-read-only=on --oltp-dist-type=uniform 2&gt;&amp;1 run                                                                                                         
</code></pre>

<h2>結果</h2>

<p>トランザクション推移</p>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=2&amp;zx=ii4lryrf8pz8"></p>

<p>レスポンスタイム推移</p>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=3&amp;zx=c2drap7b5561"></p>

<p>Fusion-IOと比べて半分ぐらい。ioDrvie Duoの公称IOPSが250,000+ IOPSでhi1.4xlargeが120,000 IOPSなので、まあ合致しますね。</p>

<p>まだ整理されてないベンチマーク結果があるので、後ほど追記しようと思います。</p>

<h2>追記 <a name="add">&nbsp;</a></h2>

<p>先日（5/17/13）の<a href="http://www.zusaar.com/event/668006">cloudpack night #6 - Re:Generate -</a>でADSJの荒木さんの発表でMySQLのパフォーマンスの話があったので<a href="https://code.launchpad.net/~percona-dev/perconatools/tpcc-mysql">tpcc-mysql</a>でベンチマークを取った資料を思い出し追記しました。</p>

<ul>
<li>500 warehouses (50GBぐらい)</li>
<li>24GB Buffer pool</li>
<li>16スレッド</li>
<li>1時間実行</li>
</ul>


<p>コマンド（ロードはかなり時間がかかるので注意）</p>

<pre><code> tpcc_load localhost tpcc root "" 500
 tpcc_start -d tpcc -u root -p "" -w 500 -c 16 -r 300 -l 3600
</code></pre>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=4&amp;zx=y6kwyezb1qth"></p>

<p>hi1.4xlargeの方が安定するまで少し時間がかかってます。<br />
以下、安定化しだした900sあたりからの数値です。</p>

<table>
<thead>
<tr>
<th></th>
<th>Fusion-IO</th>
<th>hi1.4xlarge</th>
</tr>
</thead>
<tbody>
<tr>
<td>total</td>
<td>2288758</td>
<td>1444417</td>
</tr>
<tr>
<td>avg</td>
<td>8445.6</td>
<td>5330.0</td>
</tr>
<tr>
<td>stddev</td>
<td>245.7</td>
<td>132.8</td>
</tr>
</tbody>
</table>


<p>Fusion-IOに比べて6割ってところでしょうか。
今回はSSDのephemeral disk1本で試したので、RAID0にするともうちょっと違ってくると思います。</p>
]]></content>
  </entry>
  
</feed>
